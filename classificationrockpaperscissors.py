# -*- coding: utf-8 -*-
"""ClassificationRockPaperScissors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1um9AzIAPomtlOFUSyTP9ljzILaxTtJV-
"""

!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip
!unzip rockpaperscissors.zip

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import shutil
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image as image_utils # Renamed import
from google.colab import files

base_dir = 'rockpaperscissors'
data_dir = os.path.join(base_dir, 'rps-cv-images')

train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

if os.path.exists(train_dir):
    shutil.rmtree(train_dir)
if os.path.exists(validation_dir):
    shutil.rmtree(validation_dir)

os.makedirs(train_dir)
os.makedirs(validation_dir)

categories = ['rock', 'paper', 'scissors']

for category in categories:
    category_path = os.path.join(data_dir, category)
    images = os.listdir(category_path)
    train_images, val_images = train_test_split(images, test_size=0.40, random_state=42)

    train_category_dir = os.path.join(train_dir, category)
    validation_category_dir = os.path.join(validation_dir, category)

    os.makedirs(train_category_dir)
    os.makedirs(validation_category_dir)

    for image in train_images:
        shutil.copy(os.path.join(category_path, image), os.path.join(train_category_dir, image))
    for image in val_images:
        shutil.copy(os.path.join(category_path, image), os.path.join(validation_category_dir, image))

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

import time
start_time = time.time()

max_epochs = 25
max_training_time = 1800  # 30 menit

class TimeLimitCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        if time.time() - start_time > max_training_time:
            self.model.stop_training = True

history = model.fit(
    train_generator,
    steps_per_epoch=41,  # 1314 images = batch_size * steps
    epochs=max_epochs,
    validation_data=validation_generator,
    validation_steps=28,  # 874 images = batch_size * steps
    verbose=2,
    callbacks=[TimeLimitCallback()]
)

end_time = time.time()
training_time = end_time - start_time
print(f'Total training time: {training_time:.2f} seconds')

loss, accuracy = model.evaluate(validation_generator, steps=28)
print(f'Validation accuracy: {accuracy*100:.2f}%')

def upload_and_predict_image(model):
    uploaded = files.upload()

    for fn in uploaded.keys():
        # Predict the image
        path = fn
        img = image_utils.load_img(path, target_size=(150, 150)) # Used alias
        imgplot = plt.imshow(img)
        plt.show()
        x = image_utils.img_to_array(img) # Used alias
        x = np.expand_dims(x, axis=0)
        x = x / 255.0  # Scale the image
        images = np.vstack([x])
        classes = model.predict(images, batch_size=10)
        print(fn)
        print(classes)
        class_names = ['rock', 'paper', 'scissors']
        predicted_class = class_names[np.argmax(classes)]
        print(predicted_class)

upload_and_predict_image(model)